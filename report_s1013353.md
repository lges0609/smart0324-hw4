**Hadoop distributed file system & its history**
=======
Apache Hadoop是一款支持數據密集型分佈式應用，並且採用 Apache 2.0 許可協定發佈的開源軟體框架。主要架構的部分，是根據 Google 公司發表的 MapReduce 和Google File System 的論文實作而成。

Hadoop 讓用戶可以在不了解分佈式底層細節的情況下，開發分佈式程序。充分利用集群的威力高速運算和存儲。簡單地說來，Hadoop是一個可以更容易開發和運行處理大規模數據的軟體平台。

分佈式文件系統（Hadoop Distributed File System） 則是由 Hadoop 實現，簡稱HDFS。 HDFS有著高容錯性（fault-tolerent）的特點，並且設計用來部署在低廉的（low-cost）硬體上。它提供高傳輸率（high throughput）來訪問應用程序的數據，適合那些有著超大數據集（large data set）的應用程式。

目錄
--
 1. 起源
 2. 特點
 3. 核心架構
 4. 歷史
 5. 參考資料

----------

起源
--
Hadoop由Apache Software Foundation 公司受到最先由Google Lab 開發的 [MapReduce](https://en.wikipedia.org/wiki/MapReduce) 和 [Google File System](research.google.com/archive/gfs.html)(GFS) 的啟發。於2005 年秋天作為 [Lucene](https://lucene.apache.org/core/) 的子項目[Nutch](nutch.apache.org/)的一部分正式引入。

2006 年3 月份，MapReduce 和 [Nutch Distributed File System](wiki.apache.org/nutch/NutchDistributedFileSystem) (NDFS) 分別被納入稱為Hadoop 的項目中。

Hadoop 可以解決許多要求極大伸縮性的問題。例如，如果您要 grep （grep 就像過濾器一樣。你可以給它一個要過濾的條件，它會回傳一個符回過濾條件的資料）一個10TB 的巨型文件，在傳統的系統上，這將需要很長的時間。但是 Hadoop 在設計時就考慮到這些問題，採用並行執行機制，因此能大大提高效率。

----------


特點
----

下面列舉 Hadoop Distributed File System 主要的一些特點： 

 1. 擴容能力（Scalable）：能可靠地（reliably）存儲和處理千兆字節的數據。
 2. 低成本（Economical）：可以通過普通機器（廉價的機器）組成的服務器群來分發以及處理數據。這些服務器群總計可達數千個節點。
 3. 高效率（Efficient）：通過分發數據，hadoop可以在數據所在的節點上並行處理它們，藉此增加處理速度。
 4. 可靠性（Reliable）：自動地維護數據的多份複製，並且在任務失敗後能自動地重新部署（redeploy）計算任務。

----------
核心架構
----
![enter image description here](https://hadoop.apache.org/docs/r1.2.1/images/hdfsarchitecture.gif)

Hadoop 由許多元件構成。其最底部是Hadoop Distributed File System（HDFS），它存儲Hadoop 集群中所有存儲節點上的文件。 HDFS 的上一層是 MapReduce 引擎，該引擎由 [JobTrackers](http://wiki.apache.org/hadoop/JobTracker) 和 [TaskTrackers](http://wiki.apache.org/hadoop/TaskTracker) 組成。通過對Hadoop分佈式計算平台最核心的分佈式文件系統HDFS、MapReduce處理過程，以及數據倉庫工具 [Hive](https://hive.apache.org/) 和分佈式數據庫 [Hbase](hbase.apache.org/)，基本涵蓋了Hadoop分佈式平台的所有技術核心。 

**HDFS**
對 client 而言，HDFS 就像一個傳統的分級文件系統。可以 Create、delete、move 或 rename，等等。但是HDFS 的架構是基於一組特定的節點構建的，這是由它自身的特點決定的。這些節點包括 NameNode（僅一個），它在HDFS 內部提供元數據服務；DataNode，它為HDFS 提供存儲 block。由於僅存在一個 NameNode，因此這是HDFS 的一個缺點。

存儲在HDFS 中的文件被分成 block，然後將這些 block 複製到多個 node 中（DataNode）。 Block 的大小（通常為64MB）和復制的塊數量在創建文件時由 client 決定。 NameNode 可以控制所有文件操作。 HDFS 內部的所有通信都基於標準的TCP/IP 協議。

NameNode

**NameNode**
它負責管理文件系統 namespace 和控制外部 client 的訪問。 NameNode 決定是否將文件映射到 DataNode 上的複制 block 上。對於最常見的 3 個複制 block，第一個複制 block 存儲在同一機架的不同 node 上，最後一個複制 block 存儲在不同機架的某個 node 上。

實際的 I/O 並沒有經過 NameNode ，只有表示 DataNode 和 block 的文件映射的meta data 經過 NameNode。當外部 client 發送請求要求創建文件時，NameNode 會以 block 標識和該 block 的第一個副本的 DataNode IP 地址作為回應。這個NameNode 還會通知其他將要接收該 block 的副本的 DataNode。

NameNode 在一個稱為 FsImage 的文件中存儲所有關於文件系統 namespace 的信息。這個文件和一個包含所有事務的記錄文件（EditLog）將存儲在 NameNode 的本地文件系統上。 FsImage 和EditLog 文件也需要複製副本，以防文件損壞或 NameNode 系統丟失。


**DataNode**
Hadoop 集群包含一個 NameNode 和大量DataNode。 DataNode 通常以機架的形式組織，機架通過一個交換機將所有系統連接起來。 Hadoop 的一個假設是：機架內部節點之間的傳輸速度快於機架間節點的傳輸速度。
DataNode 響應來自HDFS 客戶機的讀寫請求。它們還響應來自 NameNode 的 create、 delete 和 copy block 的命令。 NameNode 依賴來自每個 DataNode 的定期心跳（heartbeat）消息。每條消息都包含一個 block 報告，NameNode 可以根據這個報告驗證 block 映射和其他文件系統 meta data。如果DataNode 不能發送 heartbeat 消息，NameNode 將採取修復措施，重新複製在該 node 上丟失的 block。

**文件操作**
HDFS 並不是一個萬能的文件系統。它的主要目的是支持以流的形式訪問寫入的大型文件。
如果 client 想將文件寫到HDFS 上，首先需要將該文件緩存到本地的臨時存儲。如果緩存的數據大於所需的HDFS 塊大小，創建文件的請求將發送給 NameNode。 NameNode 將以DataNode 標識和目標 block 回應 client 。
同時也通知將要保存文件 block 副本的DataNode。當客戶機開始將臨時文件發送給第一個 DataNode 時，將立即通過管道方式將 block 內容轉發給副本DataNode。Client 也負責創建保存在相同HDFS namespace 中的校驗和（checksum）文件。

在最後的文件 block 發送之後，NameNode 將文件創建提交到它的持久化 meta data 存儲（在EditLog 和FsImage 文件）。

----------

歷史
--
2011年12月27日--1.0.0版本釋出。標誌著Hadoop已經初俱生產規模。
2009年4月-- 贏得每分鐘排序，59秒內排序500 GB（在1400個節點上）和173分鐘內排序100 TB數據（在3400個節點上）。
2009年3月-- 17個集群總共24 000台機器。
2008年10月-- 研究集群每天裝載10 TB的數據。
2008年4月-- 贏得世界最快1 TB數據排序在900個節點上用時209秒。
2007年4月-- 研究集群達到兩個1000個節點的集群。
2007年1月-- 研究集群到達900個節點。
2006年12月-- 標準排序在20個節點上運行1.8個小時，100個節點3.3小時，500個節點5.2小時，900個節點7.8個小時。
2006年11月-- 研究集群增加到600個節點。
2006年5月-- 標準排序在500個節點上運行42個小時（硬件配置比4月的更好）。
2006年5月-- 雅虎建立了一個300個節點的Hadoop研究集群。
2006年4月-- 標準排序（10 GB每個節點）在188個節點上運行47.9個小時。
2006年2月-- 雅虎的網格計算團隊採用Hadoop。
2006年2月-- Apache Hadoop項目正式啟動以支持MapReduce和HDFS的獨立發展。
2006年1月-- Doug Cutting加入雅虎。
2005年12月-- Nutch移植到新的框架，Hadoop在20個節點上穩定運行。
2004年-- 最初的版本（稱為HDFS和MapReduce）由Doug Cutting和Mike Cafarella開始實施。

----------

參考資料
--
 1. [Hadoop 核心架構](http://baike.baidu.com/item/Hadoop) ．百度百科
 2. [hadoop概念、子项目、历史、版本演化](http://wenku.baidu.com/view/3dc53793fd0a79563c1e722a) ．百度文庫
 3. [The Google File System](http://research.google.com/archive/gfs.html) ．Google Research Publications
 4. [Hadoop](ttps://zh.wikipedia.org/zh-tw/Apache_Hadoop)  ．維基百科
 5. [認識大數據的黃色小象幫手–– Hadoop](www.inside.com.tw/2015/03/12/big-data-4-hadoop)  ．Inside 硬塞的網路
